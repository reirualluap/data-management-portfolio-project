{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING CSV TO DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = []\n",
    "\n",
    "for n in range(1,13):\n",
    "    filename = f'./bike-rental-starter-kit/data/JC-2016{str(n).zfill(2)}-citibike-tripdata.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    csvs.append(df)\n",
    "\n",
    "weather = pd.read_csv('./bike-rental-starter-kit/data/newark_airport_2016.csv')\n",
    "\n",
    "tripdata = pd.concat(csvs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to convert a string to snake case\n",
    "def snake_case(s):\n",
    "    return '_'.join(\n",
    "        re.sub('([A-Z][a-z]+)', r' \\1',\n",
    "        re.sub('([A-Z]+)', r' \\1',\n",
    "        s.replace('-', ' '))).split()).lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TRIPDATA ------------\n",
    "\n",
    "# Parsing int64 in Int64 to normalize .info()\n",
    "for col in tripdata.columns:\n",
    "    if tripdata[col].dtypes == 'int64':\n",
    "        tripdata[col] = tripdata[col].astype('Int64')\n",
    "\n",
    "# Normalize str to title format \n",
    "for col in tripdata.columns:\n",
    "    if tripdata[col].dtypes == 'object':\n",
    "        tripdata[col] = tripdata[col].str.title()\n",
    "\n",
    "# Parsing Float64 in Int64 to normalize .info()\n",
    "tripdata['Birth Year'] = tripdata['Birth Year'].astype('Int64')\n",
    "\n",
    "# Erasing birth date for people birth before 1916\n",
    "tripdata[tripdata['Birth Year']<=1916] = None\n",
    "\n",
    "# Mapping Int64 to str values\n",
    "tripdata['Gender'] = tripdata['Gender'].map({2:'female', 1:'male'})\n",
    "\n",
    "# Keeping only trip duration under 7days long\n",
    "tripdata = tripdata[tripdata['Trip Duration'] <= 60*60*24*7]\n",
    "\n",
    "\n",
    "# Creating an UUID for tripdata\n",
    "tripdata['Ride ID'] = [str(uuid.uuid4()) for _ in range(len(tripdata))]\n",
    "\n",
    "# Mapping User Type to Casual/Member\n",
    "\n",
    "tripdata['User Type'] = tripdata['User Type'].map({'Subscriber':'Casual', 'Customer':'Member'})\n",
    "\n",
    "\n",
    "tripdata.rename(columns={\n",
    "    'Trip Duration':'Trip Duration', #KEEP\n",
    "    'Start Time':'Started at',\n",
    "    'Stop Time':'Ended at',\n",
    "    'Start Station ID':'Start station ID',\n",
    "    'Start Station Name':'Start station name',\n",
    "    'Start Station Latitude':'Start latitude',\n",
    "    'Start Station Longitude':'Start longitude',\n",
    "    'End Station ID':'End station ID',\n",
    "    'End Station Name':'End station name',\n",
    "    'End Station Latitude':'End latitude',\n",
    "    'End Station Longitude':'End Longitude',\n",
    "    'Bike ID':'Bike ID', #KEEP \n",
    "    'User Type':'User Type', #KEEP Name -- Member or casual ride\n",
    "    'Birth Year':'Birth Year', #KEEP\n",
    "    'Gender':'Gender', #KEEP\n",
    "    'Ride ID':'Ride ID' #Created\n",
    "    # Missing -- Rideable type\n",
    "})\n",
    "\n",
    "weather.rename(columns={\n",
    "    'station':'Station ID'\n",
    "    ###\n",
    "})\n",
    "\n",
    "# Snake Casing the columns name\n",
    "tripdata.columns = [snake_case(column) for column in tripdata.columns]\n",
    "\n",
    "tripdata.Name = 'tripdata'\n",
    "\n",
    "## WEATHER -------------\n",
    "\n",
    "# Splitting Name/Region from intial Name column\n",
    "weather['SPLIT'] = weather['NAME'].str.split(',')\n",
    "\n",
    "if 'REGION' in weather.columns:\n",
    "    pass\n",
    "else:\n",
    "    weather['NAME'] = weather['SPLIT'].str[0]\n",
    "    weather['REGION'] = weather['SPLIT'].str[1]\n",
    "\n",
    "# Delete SPLIT if exists\n",
    "if 'SPLIT' in weather.columns:\n",
    "    weather.drop('SPLIT', axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Normalize str to title format \n",
    "weather['NAME'] = weather['NAME'].str.title()\n",
    "\n",
    "# Drop columns where all values are NaN\n",
    "for col in weather.columns:\n",
    "    if weather[col].isnull().sum() == len(weather[col]):\n",
    "        weather.drop(col,axis=1, inplace=True)\n",
    "\n",
    "# Adding Lat/Long for weather df\n",
    "weather['Latitude'] = 40.689531\n",
    "weather['Longitude'] =-74.174462\n",
    "\n",
    "# Snake Casing the columns name\n",
    "weather.columns = [snake_case(column) for column in weather.columns]\n",
    "\n",
    "weather.Name = 'weather'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created\n",
      "Creating fact_trip table in : 0.01 seconds\n",
      "Starting data loading...\n",
      "Loading data into table in : 28.54 seconds\n",
      "DataFrame successfully loaded into the table: fact_trip \n",
      "\n",
      "Creating fact_weather table in : 0.01 seconds\n",
      "Starting data loading...\n",
      "Loading data into table in : 0.06 seconds\n",
      "DataFrame successfully loaded into the table: fact_weather \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import time\n",
    "\n",
    "# Define your PostgreSQL database connection parameters\n",
    "db_config = {\n",
    "    'user': 'python',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:{db_config[\"port\"]}/{db_config[\"database\"]}')\n",
    "print(\"Engine created\")\n",
    "\n",
    "table_dict = {\n",
    "    'tripdata' : 'fact_trip',\n",
    "    'weather' : 'fact_weather'\n",
    "}\n",
    "\n",
    "tables = [tripdata,weather]\n",
    "\n",
    "inspector = inspect(engine)\n",
    "\n",
    "for table in tables:\n",
    "\n",
    "    postgres_name = table_dict[f'{table.Name}']\n",
    "    pd_name = table.Name\n",
    "\n",
    "    if not inspector.has_table(postgres_name):\n",
    "        # Map pandas dtypes to PostgreSQL dtypes\n",
    "        dtype_mapping = {'object': 'TEXT', 'int64': 'BIGINT', 'float64': 'NUMERIC', 'bool': 'BOOLEAN', 'datetime64': 'TIMESTAMP', 'timedelta': 'INTERVAL'}\n",
    "        \n",
    "        # Convert pandas dtypes to PostgreSQL dtypes for each column\n",
    "        column_types = {col: dtype_mapping.get(str(table[col].dtype), 'TEXT') for col in table.columns}\n",
    "        \n",
    "        # Generate the CREATE TABLE SQL statement dynamically based on DataFrame columns and their types\n",
    "        create_table_sql = f\"CREATE TABLE {postgres_name} (\\n\"\n",
    "        create_table_sql += ',\\n'.join([f\"{col} {column_types[col]}\" for col in table.columns])\n",
    "        create_table_sql += \"\\n);\"\n",
    "        \n",
    "        # Execute the CREATE TABLE SQL statement\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            with engine.connect() as connection:\n",
    "                connection.execute(text(create_table_sql))\n",
    "                print(\"Creating {} table in : {} seconds\".format(postgres_name,round(time.time() - start_time,2)))\n",
    "        except OperationalError as e:\n",
    "            print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "\n",
    "        # Write the DataFrame to the PostgreSQL database\n",
    "        start_time = time.time()\n",
    "        print(\"Starting data loading...\")\n",
    "        table.to_sql(postgres_name, engine, index=False, if_exists='replace')\n",
    "        print(\"Loading data into table in : {} seconds\".format(round(time.time() - start_time,2)))\n",
    "        \n",
    "        print(f'DataFrame successfully loaded into the table: {postgres_name} \\n')\n",
    "\n",
    "    else:\n",
    "        print(f'{postgres_name} already exists in {db_config[\"database\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created\n",
      "Connected to postgres as user python\n",
      "\n",
      "Table fact_trip exists: True\n",
      "Table exists. Deleting...\n",
      "Statement used : DROP TABLE fact_trip CASCADE;\n",
      "Table fact_trip successfully deleted.\n",
      "\n",
      "Table fact_weather exists: True\n",
      "Table exists. Deleting...\n",
      "Statement used : DROP TABLE fact_weather CASCADE;\n",
      "Table fact_weather successfully deleted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_config = {\n",
    "    'user': 'python',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "engine = create_engine(f'postgresql://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:{db_config[\"port\"]}/{db_config[\"database\"]}')\n",
    "print(\"Engine created\")\n",
    "print(f'Connected to {db_config[\"database\"]} as user {db_config[\"user\"]}\\n')\n",
    "\n",
    "\n",
    "table_dict = {\n",
    "    'tripdata' : 'fact_trip',\n",
    "    'weather' : 'fact_weather'\n",
    "}\n",
    "\n",
    "tables = [tripdata,weather]\n",
    "\n",
    "for table in tables:\n",
    "\n",
    "    postgres_name = table_dict[f'{table.Name}']\n",
    "\n",
    "    inspector = inspect(engine)\n",
    "    print(f'Table {postgres_name} exists:', inspector.has_table(postgres_name))\n",
    "\n",
    "    if inspector.has_table(postgres_name):\n",
    "        print('Table exists. Deleting...')\n",
    "        drop_table_sql = f\"DROP TABLE {postgres_name} CASCADE;\"\n",
    "        print(f\"Statement used : {drop_table_sql}\")\n",
    "        \n",
    "        try:\n",
    "            with engine.connect() as connection:\n",
    "                # connection.execute(\"SET search_path TO public, public;\")\n",
    "                connection.execute(text(drop_table_sql))\n",
    "                # Commit the transaction\n",
    "                connection.commit()\n",
    "\n",
    "            print(f'Table {postgres_name} successfully deleted.\\n')\n",
    "        except Exception as e:\n",
    "            print(f'Error deleting table {postgres_name}: {e}')\n",
    "            connection.rollback()\n",
    "            raise  # This will re-raise the exception for more detailed error information\n",
    "\n",
    "    else:\n",
    "        print(f'Table {postgres_name} does not exist.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
