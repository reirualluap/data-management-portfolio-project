{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING CSV TO DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = []\n",
    "\n",
    "for n in range(1,13):\n",
    "    filename = f'./bike-rental-starter-kit/data/JC-2016{str(n).zfill(2)}-citibike-tripdata.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    csvs.append(df)\n",
    "\n",
    "weather = pd.read_csv('./bike-rental-starter-kit/data/newark_airport_2016.csv')\n",
    "\n",
    "tripdata = pd.concat(csvs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to convert a string to snake case\n",
    "def snake_case(s):\n",
    "    return '_'.join(\n",
    "        re.sub('([A-Z][a-z]+)', r' \\1',\n",
    "        re.sub('([A-Z]+)', r' \\1',\n",
    "        s.replace('-', ' '))).split()).lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TRIPDATA ------------\n",
    "\n",
    "# Parsing int64 in Int64 to normalize .info()\n",
    "for col in tripdata.columns:\n",
    "    if tripdata[col].dtypes == 'int64':\n",
    "        tripdata[col] = tripdata[col].astype('Int64')\n",
    "\n",
    "# Normalize str to title format \n",
    "for col in tripdata.columns:\n",
    "    if tripdata[col].dtypes == 'object':\n",
    "        tripdata[col] = tripdata[col].str.title()\n",
    "\n",
    "# Parsing Float64 in Int64 to normalize .info()\n",
    "tripdata['Birth Year'] = tripdata['Birth Year'].astype('Int64')\n",
    "\n",
    "# Erasing birth date for people birth before 1916\n",
    "tripdata[tripdata['Birth Year']<=1916] = None\n",
    "\n",
    "# Mapping Int64 to str values\n",
    "tripdata['Gender'] = tripdata['Gender'].map({2:'female', 1:'male'})\n",
    "\n",
    "# Keeping only trip duration under 7days long\n",
    "tripdata = tripdata[tripdata['Trip Duration'] <= 60*60*24*7]\n",
    "\n",
    "\n",
    "# Creating an UUID for tripdata\n",
    "tripdata['Ride ID'] = [str(uuid.uuid4()) for _ in range(len(tripdata))]\n",
    "\n",
    "# Mapping User Type to Casual/Member\n",
    "\n",
    "tripdata['User Type'] = tripdata['User Type'].map({'Subscriber':'Casual', 'Customer':'Member'})\n",
    "\n",
    "\n",
    "tripdata.rename(columns={\n",
    "    'Trip Duration':'Trip Duration', #KEEP\n",
    "    'Start Time':'Started at',\n",
    "    'Stop Time':'Ended at',\n",
    "    'Start Station ID':'Start station ID',\n",
    "    'Start Station Name':'Start station name',\n",
    "    'Start Station Latitude':'Start latitude',\n",
    "    'Start Station Longitude':'Start longitude',\n",
    "    'End Station ID':'End station ID',\n",
    "    'End Station Name':'End station name',\n",
    "    'End Station Latitude':'End latitude',\n",
    "    'End Station Longitude':'End Longitude',\n",
    "    'Bike ID':'Bike ID', #KEEP \n",
    "    'User Type':'User Type', #KEEP Name -- Member or casual ride\n",
    "    'Birth Year':'Birth Year', #KEEP\n",
    "    'Gender':'Gender', #KEEP\n",
    "    'Ride ID':'Ride ID' #Created\n",
    "    # Missing -- Rideable type\n",
    "})\n",
    "\n",
    "weather.rename(columns={\n",
    "    'station':'Station ID'\n",
    "    ###\n",
    "})\n",
    "\n",
    "# Snake Casing the columns name\n",
    "tripdata.columns = [snake_case(column) for column in tripdata.columns]\n",
    "\n",
    "\n",
    "## WEATHER -------------\n",
    "\n",
    "# Splitting Name/Region from intial Name column\n",
    "weather['SPLIT'] = weather['NAME'].str.split(',')\n",
    "\n",
    "if 'REGION' in weather.columns:\n",
    "    pass\n",
    "else:\n",
    "    weather['NAME'] = weather['SPLIT'].str[0]\n",
    "    weather['REGION'] = weather['SPLIT'].str[1]\n",
    "\n",
    "# Delete SPLIT if exists\n",
    "if 'SPLIT' in weather.columns:\n",
    "    weather.drop('SPLIT', axis=1, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Normalize str to title format \n",
    "weather['NAME'] = weather['NAME'].str.title()\n",
    "\n",
    "# Drop columns where all values are NaN\n",
    "for col in weather.columns:\n",
    "    if weather[col].isnull().sum() == len(weather[col]):\n",
    "        weather.drop(col,axis=1, inplace=True)\n",
    "\n",
    "# Adding Lat/Long for weather df\n",
    "weather['Latitude'] = 40.689531\n",
    "weather['Longitude'] =-74.174462\n",
    "\n",
    "# Snake Casing the columns name\n",
    "weather.columns = [snake_case(column) for column in weather.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to an existing database\n",
    "with psycopg.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    port=\"5432\"\n",
    "    ) as conn:\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS fact_trip\n",
    "        \"\"\")\n",
    "\n",
    "        # Execute a command: this creates a new table\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fact_trip (\n",
    "                ride_id uuid PRIMARY KEY,\n",
    "                bike_id bigint\n",
    "                )\n",
    "            \"\"\")\n",
    "        \n",
    "        # values = []    \n",
    "    \n",
    "        for i in range(0, len(tripdata)):\n",
    "            values = (str(tripdata['ride_id'][i]), int(tripdata['bike_id'][i]))\n",
    "            cur.execute(\"INSERT INTO fact_trip (ride_id, bike_id) VALUES (%s, %s) ON CONFLICT (ride_id) DO NOTHING\", values)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully loaded into the table: fact_trip_test\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# Define your PostgreSQL database connection parameters\n",
    "db_config = {\n",
    "    'user': 'python',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:{db_config[\"port\"]}/{db_config[\"database\"]}')\n",
    "\n",
    "# Specify the table name in the database\n",
    "table_name = 'fact_trip_test'\n",
    "\n",
    "# Check if the table exists, if not, create it\n",
    "inspector = inspect(engine)\n",
    "if not inspector.has_table(table_name):\n",
    "    # Map pandas dtypes to PostgreSQL dtypes\n",
    "    dtype_mapping = {'object': 'TEXT', 'int64': 'BIGINT', 'float64': 'NUMERIC', 'bool': 'BOOLEAN', 'datetime64': 'TIMESTAMP', 'timedelta': 'INTERVAL'}\n",
    "    \n",
    "    # Convert pandas dtypes to PostgreSQL dtypes for each column\n",
    "    column_types = {col: dtype_mapping.get(str(tripdata[col].dtype), 'TEXT') for col in tripdata.columns}\n",
    "    \n",
    "    # Generate the CREATE TABLE SQL statement dynamically based on DataFrame columns and their types\n",
    "    create_table_sql = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    create_table_sql += ',\\n'.join([f\"{col} {column_types[col]}\" for col in tripdata.columns])\n",
    "    create_table_sql += \"\\n);\"\n",
    "    \n",
    "    # Execute the CREATE TABLE SQL statement\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(text(create_table_sql))\n",
    "    except OperationalError as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "\n",
    "    # Write the DataFrame to the PostgreSQL database\n",
    "    tripdata.to_sql(table_name, engine, index=False, if_exists='replace')\n",
    "\n",
    "    print(f'DataFrame successfully loaded into the table: {table_name}')\n",
    "\n",
    "else:\n",
    "    print(f'{table_name} already exists in {db_config[\"database\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to postgres as user python\n",
      "Table fact_trip_test exists: True\n",
      "Table exists. Deleting...\n",
      "Statement used : DROP TABLE fact_trip_test CASCADE;\n",
      "Table fact_trip_test successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "# # Define your PostgreSQL database connection parameters\n",
    "db_config = {\n",
    "    'user': 'python',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{db_config[\"user\"]}:{db_config[\"password\"]}@{db_config[\"host\"]}:{db_config[\"port\"]}/{db_config[\"database\"]}')\n",
    "print(f'Connected to {db_config[\"database\"]} as user {db_config[\"user\"]}')\n",
    "\n",
    "# Specify the table name you want to delete\n",
    "table_name_to_delete = 'fact_trip_test'\n",
    "\n",
    "# Check if the table exists before attempting to delete\n",
    "inspector = inspect(engine)\n",
    "print(f'Table {table_name_to_delete} exists:', inspector.has_table(table_name_to_delete))\n",
    "\n",
    "if inspector.has_table(table_name_to_delete):\n",
    "    print('Table exists. Deleting...')\n",
    "    drop_table_sql = f\"DROP TABLE {table_name_to_delete} CASCADE;\"\n",
    "    print(f\"Statement used : {drop_table_sql}\")\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # connection.execute(\"SET search_path TO public, public;\")\n",
    "            connection.execute(text(drop_table_sql))\n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "\n",
    "        print(f'Table {table_name_to_delete} successfully deleted.')\n",
    "    except Exception as e:\n",
    "        print(f'Error deleting table {table_name_to_delete}: {e}')\n",
    "        connection.rollback()\n",
    "        raise  # This will re-raise the exception for more detailed error information\n",
    "\n",
    "else:\n",
    "    print(f'Table {table_name_to_delete} does not exist.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
